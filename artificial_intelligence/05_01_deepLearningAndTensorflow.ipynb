{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbec078",
   "metadata": {},
   "source": [
    "> 평소에 많이 한 사람이 유리하지만 계속 인공지능을 가지고 뭔가를 해 나가게 될텐데 지금 상황에서 할 수 있는 최선 그것만 생각하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b99be2",
   "metadata": {},
   "source": [
    "# 딥러닝과 텐서플로\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f623e2",
   "metadata": {},
   "source": [
    "## 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c5f51",
   "metadata": {},
   "source": [
    "##  텐서플로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2210db7",
   "metadata": {},
   "source": [
    "## 텐서플로 프로그래밍 기초\n",
    "\n",
    "sklearn의 표현 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3cd40",
   "metadata": {},
   "source": [
    "## 텐서플로로 다층 퍼셉트론 프로그래밍\n",
    "- 앞으로 케라스로 프로그래밍\n",
    "    - 케라스가 텐서플로에 편입되었으므로 텐서플로로 프로그래밍한다고 말할 것임\n",
    "- 이 절은\n",
    "    - MNIST와 fashion MNIST 데이터를 다층 퍼셉트론으로 인식하는 프로그래밍 실습\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02168474",
   "metadata": {},
   "source": [
    "## 깊은 다층 퍼셉트론\n",
    "다층 퍼셉트론에 은닉층을 더 많이 추가하면 깊은 다층 퍼셉트론\n",
    "    - 깊은 다층 퍼셉트론은 가장 쉽게 생각할 수 있는 딥러닝 모델\n",
    "\n",
    "### 구조와 동작\n",
    "- 깊은 다층 퍼셉트론DeepMLP의 구조\n",
    "\n",
    "### 오류 역전파 알고리즘\n",
    "- 다층 퍼셉트론(4.8절)의 학습 알고리즘을 조금 확장\n",
    "\n",
    "### 깊은 다층 퍼셉트론 프로그래밍\n",
    "- \n",
    "\n",
    "### 가중치 초기화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9643290",
   "metadata": {},
   "source": [
    "## 딥러닝의 학습 전략 \n",
    "0 깊은 다층 퍼셉트론의 학습 알고리즘인 식은 수학적으로 아주 깔끔\n",
    "\n",
    "### 그레이디언트 소멸 문제와 해결책\n",
    "\n",
    "### 과잉 적합과 과잉 적합 회피 전략"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a3cb42",
   "metadata": {},
   "source": [
    "## 딥러닝이 사용하는 손실 함수\n",
    "- 시험 점수의 역할\n",
    "    - 점수가 낮은 학생에게 벌점을 부여하면 자신을 성찰하고 더 열심히 공부할 동기 부여\n",
    "    - 점수가 낮거나 높거나 비슷한 벌점을 받으면 공정성이 깨지고 공부 의욕을 꺾음\n",
    "   \n",
    "- 신경망 학습도 비슷\n",
    "    - 신경망 가중치가 학생, 손실 함수가 시험 점수에 해당\n",
    "\n",
    "###  평균제곱오차MSE\n",
    "오차 제곱값 평균\n",
    "- 샘플 하나의 오류\n",
    "    - 레이블 y와 신경망이 예측한 값 o의 차이..\n",
    "    \n",
    "- 평균 제곱 오차\n",
    "    - 통계학에서 오랫동안 사용해온 식을 기계 학습이 빌려다 쓰는 셈\n",
    "    \n",
    "- 평균제곱오차의 문제점\n",
    "    - 교정에 사용하는 값, 즉 그레이디언트가 벌점에 해당. 오차 e가 더 큰데 그레이디언트가 더 작은 상황이 발생(공부를 못하는 학생이 더 높은 점수를 받는 상황)\n",
    "    - 학습이 느려지거나 학습이 안되는 상황을 초래할 가증성\n",
    "    \n",
    "\n",
    "### 교차 엔트로피\n",
    "\n",
    "> MAE 평균 절대 오차 (모든 절대 오차의 평균)\n",
    "\n",
    "엔트로피 : 정답이 나올 확률만을 대상으로 측정한 값\n",
    "\n",
    "교차 엔트로피cross entropy : 모델에서 예측한 확률과 정답확률을 모두 사용해 측정한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc3ec1",
   "metadata": {},
   "source": [
    "##  딥러닝이 사용하는 옵티마이저\n",
    "손실 함수의 최저점을 찾아주는 옵티마이저\n",
    "- 표준에 해당하는 SGD 옵티마이저를 개선하는 두 가지 아이디어\n",
    "    - 모멘텀momentum\n",
    "    - 적응적 학습률adaptive learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": "5",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.319px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
